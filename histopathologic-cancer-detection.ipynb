{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11848,"databundleVersionId":862157,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pathlib import Path\nimport random\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-29T04:50:56.923848Z","iopub.execute_input":"2025-11-29T04:50:56.924192Z","iopub.status.idle":"2025-11-29T04:50:58.546986Z","shell.execute_reply.started":"2025-11-29T04:50:56.924167Z","shell.execute_reply":"2025-11-29T04:50:58.546375Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1>Background</h1>\nIn this data competition, we need to identify metastatic cancer in small image patches taken from larger digital pathology scans.<br>\n\nThe train_labels.csv file provides the ground truth for the images in the train folder. We will use the train_labels.csv to train our models. Our goal is to predict the labels for the images in the test folder. <br>\nA positive label indicates that the center 32x32px region of a patch contains at least one pixel of cancer tissue. <br>\nThe training data includes 220025 images; their ID is something that looks like this: f38a6374c348f90b587e046aac6079959adf3835. And each image is labeled with 0 or 1 for cancer detection results.\n","metadata":{}},{"cell_type":"code","source":"TRAIN_LABELS = '/kaggle/input/histopathologic-cancer-detection/train_labels.csv'\nTRAIN_DIR = '/kaggle/input/histopathologic-cancer-detection/train'\nTEST_DIR = '/kaggle/input/histopathologic-cancer-detection/test'\nOUTPUT_DIR = Path('/kaggle/working')\ndf_train = pd.read_csv(TRAIN_LABELS)\ndf_train.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T04:51:01.682246Z","iopub.execute_input":"2025-11-29T04:51:01.682813Z","iopub.status.idle":"2025-11-29T04:51:02.028502Z","shell.execute_reply.started":"2025-11-29T04:51:01.682781Z","shell.execute_reply":"2025-11-29T04:51:02.027943Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T04:51:29.671373Z","iopub.execute_input":"2025-11-29T04:51:29.671646Z","iopub.status.idle":"2025-11-29T04:51:29.702914Z","shell.execute_reply.started":"2025-11-29T04:51:29.671624Z","shell.execute_reply":"2025-11-29T04:51:29.702029Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_train.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T04:51:31.262157Z","iopub.execute_input":"2025-11-29T04:51:31.262420Z","iopub.status.idle":"2025-11-29T04:51:31.267428Z","shell.execute_reply.started":"2025-11-29T04:51:31.262398Z","shell.execute_reply":"2025-11-29T04:51:31.266718Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"<h1>Exploratory Data Analysis (EDA)</h1>\n\n<h3>Data Structure</h3>\nFirstly, let us check the training data to see the class distribution. <br>\nFrom the visualization, we can see there are more data labeled in no tumor (0) than tumor (1). Total number is 130908 VS 89117. But overall, I think the contribution is ok for training.","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom PIL import Image, ImageDraw","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T04:51:34.120151Z","iopub.execute_input":"2025-11-29T04:51:34.120608Z","iopub.status.idle":"2025-11-29T04:51:35.546911Z","shell.execute_reply.started":"2025-11-29T04:51:34.120582Z","shell.execute_reply":"2025-11-29T04:51:35.546307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_label_counts = df_train['label'].value_counts()\nprint (train_label_counts)\nplt.figure(figsize=(6, 4))\nsns.barplot(x=train_label_counts.index, y=train_label_counts.values)\nplt.title('Class Distribution in Training Data')\nplt.xlabel('Label (0: No Cancer, 1: Cancer)')\nplt.ylabel('Count')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T04:51:36.266881Z","iopub.execute_input":"2025-11-29T04:51:36.267516Z","iopub.status.idle":"2025-11-29T04:51:36.450399Z","shell.execute_reply.started":"2025-11-29T04:51:36.267494Z","shell.execute_reply":"2025-11-29T04:51:36.449843Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3>Data Cleaning</h3>\nWe checked the training dataset, and there is no duplicate data. So we are good for data cleaning.","metadata":{}},{"cell_type":"code","source":"df_train.duplicated().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T04:51:38.276080Z","iopub.execute_input":"2025-11-29T04:51:38.276798Z","iopub.status.idle":"2025-11-29T04:51:38.340097Z","shell.execute_reply.started":"2025-11-29T04:51:38.276763Z","shell.execute_reply":"2025-11-29T04:51:38.339274Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3>Image Visualization</h3>\nWe loaded the images from training folder for both tumor case and no tumor case below. <br>\nUsing human eye is difficult to identify cancer. So let us try how the deep learning will handle these.","metadata":{}},{"cell_type":"code","source":"cancer = df_train.loc[df_train['label']==1]['id'].values\nnoncancer = df_train.loc[df_train['label']==0]['id'].values \n\nprint(cancer[0:5])\nprint(noncancer[0:5])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T04:51:44.109986Z","iopub.execute_input":"2025-11-29T04:51:44.110667Z","iopub.status.idle":"2025-11-29T04:51:44.128991Z","shell.execute_reply.started":"2025-11-29T04:51:44.110640Z","shell.execute_reply":"2025-11-29T04:51:44.128265Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def plot_fig(ids,title,nrows=5,ncols=10):\n\n    fig,ax = plt.subplots(nrows,ncols,figsize=(12,6))\n    plt.subplots_adjust(wspace=0, hspace=0) \n    for i,j in enumerate(ids[:nrows*ncols]):\n        fname = os.path.join(TRAIN_DIR ,j +'.tif')\n        img = Image.open(fname)\n        idcol = ImageDraw.Draw(img)\n        idcol.rectangle(((0,0),(95,95)),outline='white')\n        plt.subplot(nrows, ncols, i+1) \n        plt.imshow(np.array(img))\n        plt.axis('off')\n\n    plt.suptitle(title, y=0.94)\n\n\nplot_fig(cancer,'Cancer Cases')\nplot_fig(noncancer,'Noncancer Cases')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T04:51:47.014084Z","iopub.execute_input":"2025-11-29T04:51:47.014347Z","iopub.status.idle":"2025-11-29T04:51:50.648643Z","shell.execute_reply.started":"2025-11-29T04:51:47.014327Z","shell.execute_reply":"2025-11-29T04:51:50.647578Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1>Deep Learning Models</h1>\nWe start preparing the cancer dataset, get RGB image and id for both training and test folders' images.\n\n<h2>Compare 3 Models</h2>\n<h3>1. TinyCNN</h3>\nTinyCNN is a lightweight CNN with 3 convolution levels. Using ReLu for activation and max pooling.\n<h3>2. Logistic CNN</h3>\nLogistic CNN is using only 1 convolution level. No activation and using global average pooling.\n<h3>3. ResNet18</h3>\nResNet18 is a more advanced model with residual connections. The skip connection solves vanishing gradients and allows deeper feature learning.\n\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport pytorch_lightning as pl\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets, transforms\nfrom sklearn.model_selection import train_test_split\nfrom pytorch_lightning.callbacks import ModelCheckpoint\nfrom sklearn.metrics import roc_auc_score\nfrom torchvision.models import resnet18\nfrom torchmetrics.classification import BinaryAUROC\n\nSEED = 42\nrandom.seed(SEED)\nnp.random.seed(SEED)\ntorch.manual_seed(SEED)\npl.seed_everything(SEED)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T04:51:50.649917Z","iopub.execute_input":"2025-11-29T04:51:50.650131Z","iopub.status.idle":"2025-11-29T04:52:04.138321Z","shell.execute_reply.started":"2025-11-29T04:51:50.650113Z","shell.execute_reply":"2025-11-29T04:52:04.137769Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CancerDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None):\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.img_dir, row[\"id\"] + \".tif\")\n        img = Image.open(img_path).convert(\"RGB\")\n\n        if self.transform:\n            img = self.transform(img)\n\n        label = int(row[\"label\"])\n        return img, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T04:52:04.139376Z","iopub.execute_input":"2025-11-29T04:52:04.139802Z","iopub.status.idle":"2025-11-29T04:52:04.145126Z","shell.execute_reply.started":"2025-11-29T04:52:04.139779Z","shell.execute_reply":"2025-11-29T04:52:04.144448Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class CancerTestDataset(Dataset):\n    def __init__(self, img_dir, transform=None):\n        self.img_dir = img_dir\n        self.img_ids = sorted(os.listdir(img_dir))\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.img_ids)\n\n    def __getitem__(self, idx):\n        img_id = self.img_ids[idx]\n        img_path = os.path.join(self.img_dir, img_id)\n        img = Image.open(img_path).convert(\"RGB\")\n\n        if self.transform:\n            img = self.transform(img)\n\n        return img, img_id.replace(\".tif\", \"\")\n\ntest_tf = transforms.Compose([\n    transforms.Resize((96, 96)),\n    transforms.ToTensor(),\n])\n\ntest_ds = CancerTestDataset(TEST_DIR, transform=test_tf)\ntest_loader = DataLoader(test_ds, batch_size=64, shuffle=False, num_workers=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T04:52:04.145833Z","iopub.execute_input":"2025-11-29T04:52:04.146113Z","iopub.status.idle":"2025-11-29T04:52:07.579171Z","shell.execute_reply.started":"2025-11-29T04:52:04.146092Z","shell.execute_reply":"2025-11-29T04:52:07.578367Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TinyCNN(pl.LightningModule):\n    def __init__(self, lr=1e-3):\n        super().__init__()\n        self.lr = lr\n\n        # --- MODEL ---\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 16, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),   # 48x48\n            nn.Conv2d(16, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2), # 24x24\n            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2), # 12x12\n        )\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(64 * 12 * 12, 128),\n            nn.ReLU(),\n            nn.Linear(128, 1)\n        )\n\n        # --- METRICS ---\n        self.train_auc = BinaryAUROC()\n        self.val_auc = BinaryAUROC()\n\n    # Forward\n    def forward(self, x):\n        return self.classifier(self.encoder(x))\n\n    # Training\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x).squeeze(1)\n        loss = F.binary_cross_entropy_with_logits(y_hat, y.float())\n\n        # AUC update\n        preds = torch.sigmoid(y_hat)\n        self.train_auc.update(preds, y.int())\n\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def on_train_epoch_end(self):\n        auc = self.train_auc.compute()\n        self.log(\"train_auc\", auc, prog_bar=True)\n        self.train_auc.reset()\n\n    # Validation\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        y_hat = self(x).squeeze(1)\n        loss = F.binary_cross_entropy_with_logits(y_hat, y.float())\n\n        preds = torch.sigmoid(y_hat)\n        self.val_auc.update(preds, y.int())\n\n        self.log(\"val_loss\", loss, prog_bar=True)\n        return loss\n\n    def on_validation_epoch_end(self):\n        auc = self.val_auc.compute()\n        self.log(\"val_auc\", auc, prog_bar=True)\n        self.val_auc.reset()\n\n    # Optimizer\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.lr)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T04:52:07.580751Z","iopub.execute_input":"2025-11-29T04:52:07.580977Z","iopub.status.idle":"2025-11-29T04:52:07.590610Z","shell.execute_reply.started":"2025-11-29T04:52:07.580959Z","shell.execute_reply":"2025-11-29T04:52:07.590081Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class LogisticCNN(pl.LightningModule):\n    def __init__(self, lr=1e-3):\n        super().__init__()\n        self.lr = lr\n\n        self.conv = nn.Conv2d(3, 1, kernel_size=1)\n\n        # Add AUC metric\n        self.val_auc = BinaryAUROC()\n\n    def forward(self, x):\n        x = self.conv(x)\n        x = x.mean(dim=[2, 3])\n        return x\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x).squeeze(1)\n        loss = F.binary_cross_entropy_with_logits(logits, y.float())\n        self.log(\"train_loss\", loss)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x).squeeze(1)\n        loss = F.binary_cross_entropy_with_logits(logits, y.float())\n\n        # update AUC (needs probabilities, not logits)\n        probs = torch.sigmoid(logits)\n        self.val_auc.update(probs, y.int())\n\n        self.log(\"val_loss\", loss, prog_bar=True)\n        return loss\n\n    def on_validation_epoch_end(self):\n        auc = self.val_auc.compute()\n        self.log(\"val_auc\", auc, prog_bar=True)\n        self.val_auc.reset()\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.lr)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T04:52:07.591463Z","iopub.execute_input":"2025-11-29T04:52:07.592176Z","iopub.status.idle":"2025-11-29T04:52:07.610038Z","shell.execute_reply.started":"2025-11-29T04:52:07.592152Z","shell.execute_reply":"2025-11-29T04:52:07.609513Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ResNet18(pl.LightningModule):\n    def __init__(self, lr=1e-4, pretrained=False):\n        super().__init__()\n        self.save_hyperparameters()\n\n        self.model = resnet18(weights=\"DEFAULT\" if pretrained else None)\n        num_features = self.model.fc.in_features\n        self.model.fc = nn.Linear(num_features, 1)\n\n        self.val_auc = BinaryAUROC()\n\n    def forward(self, x):\n        return self.model(x).squeeze(1)\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = F.binary_cross_entropy_with_logits(logits, y.float())\n        self.log(\"train_loss\", loss, prog_bar=True)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        logits = self(x)\n        loss = F.binary_cross_entropy_with_logits(logits, y.float())\n\n        probs = torch.sigmoid(logits)\n        self.val_auc.update(probs, y.int())\n\n        self.log(\"val_loss\", loss, prog_bar=True)\n        return loss\n\n    def on_validation_epoch_end(self):\n        auc = self.val_auc.compute()\n        self.log(\"val_auc\", auc, prog_bar=True)\n        self.val_auc.reset()\n\n    def configure_optimizers(self):\n        return torch.optim.Adam(self.parameters(), lr=self.hparams.lr)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T04:52:07.610720Z","iopub.execute_input":"2025-11-29T04:52:07.611003Z","iopub.status.idle":"2025-11-29T04:52:07.628612Z","shell.execute_reply.started":"2025-11-29T04:52:07.610981Z","shell.execute_reply":"2025-11-29T04:52:07.628045Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h1>Results and Analysis</h1>\n\nLet's check the performance result AUC for each model.<br>\n<h4>TinyCNN VAL AUC: 0.96970</h4>\n<h4>LogisticCNN VAL AUC: 0.63776</h4>\n<h4>ResNet18 VAL AUC: 0.97673</h4>\n\nOverall, ResNet18 performs best. It has a deeper architecture and can capture more complex features. <br>\n\nFor TinyCNN and LogisticCNN, they are more straightforward, but may be because of limited convolution levels, they may lost more information during the process.<br>\nEspecially, the logisticCNN with only 1 convolution level, its performance is poor.<br>\n\nFurthermore, I optimize ResNet with different learning rates and epochs.\n ","metadata":{}},{"cell_type":"code","source":"def train_and_evaluate(model, train_loader, val_loader, max_epochs=5, ckpt_name='model.ckpt'):\n    ckpt_cb = ModelCheckpoint(dirpath=str(OUTPUT_DIR), filename=ckpt_name, monitor='val_auc', mode='max', save_top_k=1)\n    trainer = pl.Trainer(max_epochs=max_epochs, accelerator='auto', devices='1', callbacks=[ckpt_cb], logger=False)\n    trainer.fit(model, train_loader, val_loader)\n    best_path = ckpt_cb.best_model_path\n    # load best for inference\n    if best_path and os.path.exists(best_path):\n        best = model.__class__.load_from_checkpoint(best_path)\n    else:\n        best = model\n    return trainer, best, best_path","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T04:52:07.629282Z","iopub.execute_input":"2025-11-29T04:52:07.629458Z","iopub.status.idle":"2025-11-29T04:52:07.645460Z","shell.execute_reply.started":"2025-11-29T04:52:07.629443Z","shell.execute_reply":"2025-11-29T04:52:07.644718Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"models_to_run = {\n'TinyCNN': TinyCNN(lr=1e-3),\n'LogisticCNN': LogisticCNN(lr=1e-3),\n'ResNet18': ResNet18(lr=1e-4, pretrained=False)\n}\n\n\nhistory = {}\nckpt_paths = {}\n\n\nfor name, model in models_to_run.items():\n    print('Training:', name)\n    trainer, best_model, best_path = train_and_evaluate(model, train_loader, val_loader, max_epochs=5, ckpt_name=f'{name}-best')\n    ckpt_paths[name] = best_path\n\n\n    # evaluate on val set to collect preds for plotting & metrics\n    best_model = best_model.to(device)\n    best_model.eval()\n    preds = []\n    targets = []\n    with torch.no_grad():\n        for x,y in val_loader:\n            x = x.to(device)\n            logits = best_model(x)\n            probs = torch.sigmoid(logits).cpu().numpy().ravel()\n            preds.extend(probs.tolist())\n            targets.extend(y.numpy().tolist())\n\n\n    auc = roc_auc_score(targets, preds)\n    history[name] = {'val_preds': preds, 'val_targets': targets, 'val_auc': auc}\n    print(f'{name} VAL AUC: {auc:.5f}, checkpoint: {best_path}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T04:52:27.617482Z","iopub.execute_input":"2025-11-29T04:52:27.618145Z","iopub.status.idle":"2025-11-29T05:32:11.670441Z","shell.execute_reply.started":"2025-11-29T04:52:27.618123Z","shell.execute_reply":"2025-11-29T05:32:11.669285Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('Loading labels...')\ndf = pd.read_csv(TRAIN_LABELS)\nprint('Total samples:', len(df), 'Positives:', df['label'].sum())\n\ntrain_tf = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.Resize((96, 96)),\n    transforms.ToTensor(),\n])\n\nval_tf = transforms.Compose([\n    transforms.Resize((96, 96)),\n    transforms.ToTensor(),\n])\n\ntrain_df, val_df = train_test_split(df, test_size=0.08, stratify=df['label'], random_state=SEED)\nprint('Train:', len(train_df), 'Val:', len(val_df))\n\n\nBATCH = 64\ntrain_ds = CancerDataset(train_df, TRAIN_DIR, transform=train_tf)\nval_ds = CancerDataset(val_df, TRAIN_DIR, transform=val_tf)\ntrain_loader = DataLoader(train_ds, batch_size=BATCH, shuffle=True, num_workers=4, pin_memory=True)\nval_loader = DataLoader(val_ds, batch_size=BATCH, shuffle=False, num_workers=4, pin_memory=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T04:52:26.845511Z","iopub.execute_input":"2025-11-29T04:52:26.846227Z","iopub.status.idle":"2025-11-29T04:52:27.131649Z","shell.execute_reply.started":"2025-11-29T04:52:26.846201Z","shell.execute_reply":"2025-11-29T04:52:27.130926Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, auc as skauc\nplt.figure(figsize=(8,6))\nfor name, h in history.items():\n    fpr, tpr, _ = roc_curve(h['val_targets'], h['val_preds'])\n    roc_auc = skauc(fpr, tpr)\n    plt.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.3f})')\n\nplt.plot([0,1],[0,1],'k--')\nplt.xlim([0.0,1.0])\nplt.ylim([0.0,1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curves on Validation Set')\nplt.legend(loc='lower right')\nplt.grid(True)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T05:32:23.719228Z","iopub.execute_input":"2025-11-29T05:32:23.719559Z","iopub.status.idle":"2025-11-29T05:32:23.929421Z","shell.execute_reply.started":"2025-11-29T05:32:23.719529Z","shell.execute_reply":"2025-11-29T05:32:23.928808Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<h3>Optimization</h3>\nLet's optimize ResNet18 by changing the learning rates and epochs. For ResNet18, it requires more epochs to reach a good result comparing with TinyCNN or LogisticCNN. So I am increase the epochs (6, 8, 10) and test with different learning rates (1e-4, 5e-4, 1e-3).<br>\nThe result below shows when learning rate is 5e-4 and epochs is 10, it got the best AUC result: <br>Best model by VAL AUC: ResNet18_lr=0.0005_ep=10 AUC = 0.9889461398124695.<br>\nBut when I applied this best model to testing, the final result for test dataset is worse. Score is 0.9084. It is less than the previous v2, ResNet with 0.0001 and 5 epochs. So it is clearly overfitting.","metadata":{}},{"cell_type":"code","source":"def evaluate_model(model_class, lr, train_loader, val_loader, epochs=5):\n    print(f\"\\n=== Testing {model_class.__name__} lr={lr}, epochs={epochs} ===\")\n\n    model = model_class(lr=lr)\n\n    trainer = pl.Trainer(\n        max_epochs=epochs,\n        accelerator=\"auto\",\n        devices=1,\n        logger=False,\n        enable_checkpointing=False\n    )\n\n    trainer.fit(model, train_loader, val_loader)\n\n    auc = trainer.callback_metrics.get(\"val_auc\")\n    return float(auc) if auc is not None else None\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T05:32:53.446651Z","iopub.execute_input":"2025-11-29T05:32:53.447439Z","iopub.status.idle":"2025-11-29T05:32:53.452356Z","shell.execute_reply.started":"2025-11-29T05:32:53.447409Z","shell.execute_reply":"2025-11-29T05:32:53.451617Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lr_list = [1e-4, 5e-4, 1e-3]\nepoch_list = [6, 8, 10]\n\nresnet_tuning_results = []\n\nfor lr in lr_list:\n    for ep in epoch_list:\n        auc = evaluate_model(ResNet18, lr, train_loader, val_loader, epochs=ep)\n        resnet_tuning_results.append({\n            \"model\": \"ResNet18\",\n            \"lr\": lr,\n            \"epochs\": ep,\n            \"val_auc\": auc\n        })\n\nresnet_tuning_results = pd.DataFrame(resnet_tuning_results)\n\nfor row in resnet_tuning_results.to_dict(\"records\"):\n    name = f\"ResNet18_lr={row['lr']}_ep={row['epochs']}\"\n    history[name] = {\"val_auc\": row[\"val_auc\"]}\n\nbest_name = max(history.keys(), key=lambda n: history[n]['val_auc'])\nbest_auc = history[best_name]['val_auc']\n\nprint(\"Best model by VAL AUC:\", best_name, \"AUC =\", best_auc)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T05:32:56.409898Z","iopub.execute_input":"2025-11-29T05:32:56.410483Z","iopub.status.idle":"2025-11-29T08:04:42.177657Z","shell.execute_reply.started":"2025-11-29T05:32:56.410458Z","shell.execute_reply":"2025-11-29T08:04:42.176937Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def rebuild_model_from_name(name):\n    if \"ResNet18\" in name and \"lr\" in name:\n        # Extract hyperparameters\n        parts = name.replace(\"ResNet18_\", \"\").split(\"_\")\n        lr = float(parts[0].split(\"=\")[1])\n        ep = int(parts[1].split(\"=\")[1])\n\n        print(f\"Retraining best tuned ResNet18 for inference: lr={lr}, epochs={ep}\")\n        model = ResNet18(lr=lr)\n\n        trainer = pl.Trainer(max_epochs=ep, accelerator=\"auto\", devices=1, logger=False)\n        trainer.fit(model, train_loader, val_loader)\n        return model\n\n    # fallback for checkpointed models\n    if ckpt_paths.get(name) and os.path.exists(ckpt_paths[name]):\n        return models_to_run[name].__class__.load_from_checkpoint(ckpt_paths[name])\n\n    return models_to_run[name]\n\nfinal_model = rebuild_model_from_name(best_name)\nfinal_model = final_model.to(device)\nfinal_model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T08:31:06.976551Z","iopub.execute_input":"2025-11-29T08:31:06.977395Z","iopub.status.idle":"2025-11-29T08:52:37.499005Z","shell.execute_reply.started":"2025-11-29T08:31:06.977362Z","shell.execute_reply":"2025-11-29T08:52:37.498275Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"ids = []\nprobs = []\n\nwith torch.no_grad():\n    for x, img_ids in test_loader:\n        x = x.to(device)\n        logits = final_model(x)\n        p = torch.sigmoid(logits).cpu().numpy().ravel()\n        ids.extend(img_ids)\n        probs.extend(p.tolist())\n\nsubmission = pd.DataFrame({'id': ids, 'label': probs})\nsubmission_path = OUTPUT_DIR / 'submission.csv'\nsubmission.to_csv(submission_path, index=False)\nprint(\"Saved submission to\", submission_path)\n\nprint(\"\\nSummary of Validation AUCs\")\nprint(\"-\" * 40)\n\nfor name, info in history.items():\n    print(f\"{name:35s} AUC = {info['val_auc']:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-29T09:02:20.756940Z","iopub.execute_input":"2025-11-29T09:02:20.757208Z","iopub.status.idle":"2025-11-29T09:06:16.679519Z","shell.execute_reply.started":"2025-11-29T09:02:20.757191Z","shell.execute_reply":"2025-11-29T09:06:16.678652Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pd.read_csv('/kaggle/working/submission.csv')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"markdown","source":"<h1>Conclusion</h1>\n\nIn this project, we compared several convolutional neural network architecturesâ€”including TinyCNN, LogisticCNN, and ResNet18 and evaluated how different hyperparameters, particularly the learning rate and number of training epochs, influenced model performance.<br>\nOverall, ResNet18 provided the strongest performance. But more epochs doesn't help a lot for ResNet18 Model, maybe because it is a deeper architecture and the epochs doesn't helps a lot for this stable architecture. Instead, it create an overfitting issue.Future work could extend this analysis using automated hyperparameter search methods to further optimize model performance.\n\n<h1>Reference</h1>\nResNet18: https://docs.pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html <br>\nAUROC: https://lightning.ai/docs/torchmetrics/stable/classification/auroc.html","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}